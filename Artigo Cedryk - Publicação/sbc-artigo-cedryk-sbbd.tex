\documentclass[12pt]{article}

\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage{subcaption}
     
\sloppy

\title{Análise de Escalabilidade Horizontal em um~\emph{cluster}  Hbase}

%\author{Omitido~\inst{1}}
\author{Cedryk Augusto dos Santos~\inst{1}, Bruno Santos de Lima~\inst{1}, Leandro Ungari Cayres~\inst{1},\\Rogério Eduardo Garcia~\inst{1}, Celso Olivete Junior~\inst{1}, Danilo Medeiros Eler~\inst{1},\\ Ronaldo Celso Messias Correia~\inst{1}}

%\address{Omitido}

\address{Faculdade de Ciências e Tecnologia -- Universidade Estadual Paulista (UNESP)\\
  Presidente Prudente -- SP -- Brasil
  \email{cedrykaugusto@gmail.com, \{bruno.s.lima,leandro.ungari\}@unesp.br,}\vspace{-0.4cm}
  \email{\{rogerio.garcia,celso.olivete,danilo.eler,ronaldo.correia\}@unesp.br}
}

\begin{document} 

\maketitle

%Resumo maximo 10 linhas.
%Se o artigo estiver em português o abstract deve estar localizado antes do resumo.

\begin{abstract}
Horizontal Scalability allows resources to be distributed by the addition of nodes, being made more flexible by the NoSQL Database. This work evaluates the horizontal scaling potential of a Hbase Database cluster, through a benchmarking in several scenarios, an ideal scenario is obtained, in order to verify the efficiency and availability of applications regardless of storage demand, operations and addition of we. The results indicate that scalability is more evident, except in scan operations, in sets of 100,000 and 1,000,000 records, in increasing the number of nodes from 1 to 2 and from 2 to 3. In the search operations, there is no improvement performance from the insertion of nodes.
\end{abstract}
     
\begin{resumo} 
O Escalonamento Horizontal permite que recursos sejam distribuídos pela adição de nós, sendo flexibilizado pelos Banco de Dados NoSQL. Este trabalho avalia o potencial de escalonamento horizontal de um cluster do Banco de Dados Hbase, através de um benchmarking em diversos cenários é obtido um cenário ideal, de modo a verificar a eficiência e disponibilidade de aplicações independentemente da demanda de armazenamento, operações e adição de nós. Os resultados indicam que a escalabilidade é mais evidente, exceto em operações scan, em conjuntos de 100.000 e 1.000.000 de registros, no aumento do número de nós de 1 para 2 e de 2 para 3. Nas operações de busca, não há melhora de desempenho a partir da inserção de nós.

%(ANTIGO)Os Bancos de Dados~\emph{NoSQL} são mais flexíveis perante o escalonamento horizontal, possibilitando a distribuição de recursos com a adição de nós. Este trabalho avalia o potencial do escalonamento horizontal de um~\emph{cluster} do Banco de Dados Hbase, através de um~\emph{benchmarking} em diversos cenários, configurando um cenário ideal, de modo a verificar a eficiência e disponibilidade de aplicações independentemente da demanda de armazenamento, operações e adição nós. Os resultados demonstram que a escalabilidade é mais evidente, exceto em operações~\emph{scan}, em conjuntos de 100.000 e 1.000.000 de registros de 1KB cada, no aumento do número de nós de 1 para 2 e, de 2 para 3. Nas operações de busca, não há melhora no desempenho a partir da inserção de nós.
\end{resumo}


\section{Introdução}
\label{sec:introducao}
 
Um dos grandes desafios computacionais consiste no armazenamento, recuperação e disponibilidade de dados de modo eficiente. Durante muitos anos, a solução majoritária foi a adoção dos Sistemas Gerenciadores de Banco de Dados Relacionais (SGBDR), que garantem o conjunto de propriedades ACID (Atomicidade, Consistência, Isolamento e Durabilidade). Contudo, os SGBDR’s não satisfazem as necessidades de sistemas no âmbito de~\emph{Big Data}.%~\cite{brito2010bancos}.
 
O~\textit{Big Data} se refere ao grande volume de dados gerados em diversos domínios de aplicação~\cite{han2011survey}. A tecnologia relacional possui fragilidade no tratamento de dados semi-estruturados e não-estruturados, além de dificuldade de distribuição devido a atender as propriedades ACID~\cite{aparicio:2016}. 
A complexidade lógica existente na modelagem relacional somada ao alto volume de dados mostrou-se um problema, visto que pode propiciar \textit{deadlocks}, além de problemas de concorrência, lentidão na leitura e escrita dos dados~\cite{han2011survey}. 
Como alternativa surgiram os Bancos de Dados \textit{NoSQL}, que atuam de modo mais eficiente com o armazenamento e manipulação de grande volume de dados, possibilitando escalar operações por diversos servidores, além de prover maior flexibilidade~\cite{ramesh:2016}.

Neste contexto, o objetivo do trabalho consiste analisar o potencial de escalabilidade horizontal de um~\emph{cluster} executando o Banco de Dados~\emph{NoSQL} HBase. Foram conduzidos testes em diferentes cenários de implementação do~\emph{cluster}, com o intuito de obter um cenário ideal, em que aplicações e serviços se mantenham eficientes e disponíveis independentemente da demanda de armazenamento e consultas, apenas pela adição de nós ao ambiente distribuído. Os testes foram conduzidos por meio de um~\emph{benchmarking} com operações~\emph{read},~\emph{write},~\emph{scan} e~\emph{read-modify-write} utilizando o \textit{framework}~\emph{Yahoo! Cloud Serving Benchmark} (YCSB) e variação do ambiente.

%Neste contexto, o objetivo deste trabalho consiste em verificar o potencial desse novo paradigma de armazenamento e recuperação de dados utilizando computação distribuída, de modo a criar um cenário, em que aplicações e serviços se mantenham eficientes e disponíveis independentemente do tamanho da demanda de armazenamento e consultas, somente através da adição de novos nós ao ambiente distribuído. Desse modo, através de um experimento foi avaliada a escalabilidade horizontal do Banco de Dados Hbase, foi executado um~\emph{benchmarking} com operações~\emph{read},~\emph{write},~\emph{scan} e~\emph{read-modify-write} utilizando o \textit{framework}~\emph{Yahoo! Cloud Serving Benchmark} (YCSB) a partir da inserção de novos nós ao sistema e crescimento do conjunto de dados.

O HBase está integrado a plataforma Hadoop, também composta por sistema de arquivos distribuídos~\emph{Hadoop Distributed File System} (HDFS) e o modelo de suporte a programação paralela MapReduce~\cite{hadoophbase}. O Hbase permite o processamento distribuído por meio de~\emph{clusters}, atuando sobre o HDFS de modo a prover recursos semelhantes ao BigTable~\cite{chang2008bigtable} e alta tolerância a falhas ao armazenar grandes quantidades de dados esparsos~\cite{hadoophbase}.

Este trabalho está organizando do seguinte modo: Na Seção~\ref{sec:fundamentacao} são apresentados conceitos de escalabilidade em banco de dados e as ferramentas utilizadas; A Seção~\ref{sec:relacionados} expõe os trabalhos relacionados; Na Seção~\ref{sec:conf-experimento} é apresentada a configuração do experimento descrevendo os cenários de testes utilizados; A Seção~\ref{sec:resultados} exibe a análise dos resultados obtidos; Por fim, a Seção~\ref{sec:finais} apresenta as considerações finais.

\section{Fundamentação Teórica}
\label{sec:fundamentacao}

\subsection{Escalabilidade em Banco de Dados}
\label{subsec:escalabilidade}

Escalabilidade é a capacidade de expandir os recursos (armazenamento e processamento) de um sistema~\cite{elmasri2010fundamentals}. Um Banco de Dados escalável possui a capacidade de manipular maior quantidade de dados e garantir a disponibilidade do sistema. Existem duas abordagens para escalabilidade:~\emph{Vertical} e~\emph{Horizontal}.

A~\emph{Escalabilidade Vertical} consiste em adicionar mais recursos ao servidor, a qual prove menor consumo de energia, implementação facilitada e menores problemas de arrefecimento. Contudo, possui custo extremamente superior a escalabilidade horizontal, além de possibilitar a interrupção do serviço por falha devido a um único servidor~\cite{hwang2014scale}. Em contraponto, na~\emph{Escalabilidade Horizontal}, os recursos são distribuídos em diferentes servidores, em geral máquinas simples, com o propósito de redução de custos. Existe garantia de recuperação em caso de falhas, devido a presença de redundância de dados e processos em diversos nós. Essa arquitetura é presente em diversos Banco de Dados~\textit{NoSQL}~\cite{hwang2014scale}.

\subsection{Apache Hadoop}
\label{subsection:hadoop}

O Apache Hadoop consiste em um (\textit{framework}) para processamento distribuído de grande volume de dados em~\emph{clusters}. Utiliza o modelo~\emph{MapReduce}, projetado para escalonamento horizontal, oferecendo alta disponibilidade e recuperação de falhas~\cite{hadoophbase}. Um~\emph{cluster} Hadoop opera sob a arquitetura mestre/escravo -- Figura~\ref{figure:hadoop}. Existem cinco processos, o~\emph{NameNode} e o~\emph{JobTraker} são processos executados pelo nó-mestre, enquanto~\emph{SecondaryNameNode} pelo nó-mestre alternativo, em caso de falha. O~\emph{DataNode} e~\emph{TaskTraker} atuam como processos escravos de múltiplas instâncias. %Os processos~\emph{NameNode},~\emph{SecondaryNameNode} e~\emph{DataNode} fazem parte da execução do sistema de arquivos HDFS, enquanto~\emph{JobTraker} e~\emph{TaskTraker} parte da execução MapReduce~\cite{goldman2012apache}.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\textwidth]{images/hadoop.png}
\caption{Estrutura dos processos do Hadoop~\cite{goldman2012apache}.}
\label{figure:hadoop}
\end{figure}

%\subsection{HDFS}
%\label{subsec:hdfs}

%O HDFS consiste em um sistema de arquivos distribuídos projetado para ser tolerante a falhas, voltado para~\emph{hardwares} de baixo custo e aplicações com grande volume de dados. Assim como um sistema de arquivos, o HDFS fornece operações de armazenamento, organização, nomeação, atribuição de permissões de acesso, compartilhamento e recuperação de forma transparente ao usuário, porém, o diferencial está no armazenamento dos arquivos, os quais compartilhados por máquinas remotas ligadas em rede.

%O processo~\emph{NameNode} tem responsabilidade pela abertura, fechamento ou renomeação de arquivos e diretórios; realizar o controle de acesso dos arquivos, armazenar metadados, coordenar a fragmentação dos arquivos em blocos, assim como a distribuição dos mesmos dentro dos processos~\emph{DataNodes}. Os processos~\emph{DataNode} tem a tarefa de armazenar os dados, responder as solicitações de leitura e escrita dos clientes e aplicações, criar, remover ou replicar blocos sob orientação do~\emph{NameNode}. Além de armazenar, os~\emph{DataNode} precisam se comunicar constantemente com o~\emph{NameNode} para manter o mapeamento dos blocos atualizado e livre de falhas~\cite{hadoophdfs}.

\subsection{HBase}
\label{subsec:hbase}

O Hbase é um banco de dados~\textit{NoSQL}, distribuído, tolerante a falhas de código aberto e altamente escalável, com foco em aplicações que necessitam de leitura e escrita de acesso aleatório com tempo constante~\cite{hadoophbase}. O projeto foi inspirado no \textit{BigTable} da Google, ambos utilizam o modelo de dados orientado a colunas. Esse não possui nenhuma linguagem de consulta estruturada, que fornece uma API Java que possibilita realizar operações básicas como~\emph{put},~\emph{get},~\emph{update} e~\emph{delete}, e também o uso da função~\emph{scan}, para selecionar quais as colunas retornadas ou o número de versões de cada célula, porém consultas mais complexas utilizam~\emph{jobs} do MapReduce.

Os dados do HBase são armazenados como arquivos do HDFS, um sistema de arquivos distribuídos tolerante a falhas, voltado para~\emph{hardwares} de baixo custo e aplicações com grande volume de dados. Dessa forma, os servidores escravos (\emph{region servers}) são dispostos nos nós que executam os processos~\emph{DataNode} do HDFS provendo localidade nos dados que transitam de um para o outro.

\subsection{Yahoo! Cloud Serving Benchmark}
\label{subsec:ycsb}

O YCSB (\emph{Yahoo!Cloud Serving Benchmark}) é um \textit{framework} de~\emph{benchmarking} para bancos de dados distribuídos, que permite a adição de novas implementações~\cite{cooper2010benchmarking}. 
O YCSB possibilita a avaliação de duas camadas de~\textit{benchmark}: performance e escalabilidade. 
Em performance, mede-se a latência (tempo de execução) das requisições, enquanto a escalabilidade é medido o impacto na performance quando o número de servidores do sistema cresce~\cite{cooper2010benchmarking}.

Esse possui um conjunto de~\emph{workloads} denominado~\emph{Core Package} e uma aplicação chamada YCSB \textit{Client}. 
As~\emph{workloads} consistem de combinações de operações de leitura e escrita, na execução de uma~\emph{workload}, o YCSB \textit{Client} cria um conjunto de dados e submete as requisições ao banco de dados~\cite{cooper2010benchmarking}.

\section{Trabalhos Relacionados} 
\label{sec:relacionados}

%Na literatura alguns trabalhos relacionados também avaliam o desempenho da ferramenta Hbase por meio de \textit{benchmarking} com outros Bancos de Dados ou ainda colocando alguma condição sobre os dados a serem manipulados.

%Em seu estudo, 
\cite{jogi2016performance} realizam a comparação MySQL com Cassandra e Hbase em operações~\emph{heavy~\emph{write}}, utilizando uma aplicação~\emph{web} REST (\emph{Representacional State Transfer}) para recebimento dos dados e armazenamento no Banco de Dados. 
Conclui-se que o Cassandra apresentou melhor velocidade de escrita, enquanto o Hbase foi duas vezes mais rápido que o MySQL, isso ocorre devido a incorporação de características do \emph{BigTable} do Google e do DynamoDB pelo Cassandra. 
\cite{swaminathan2016quantitative} analisaram a escalabilidade nos Bancos de Dados: Hbase, Cassandra e MongoDB, utilizando o \textit{framework} YCSB com diferentes cargas de trabalho e conjunto de dados, no intuito de evidenciar as vantagens e desvantagens de cada em cenários específicos.

Segundo~\cite{waage2014benchmarking}, a confiabilidade para o armazenamento ``em nuvem'' é um dos pontos chaves para adoção de tecnologias não-relacionais. 
Foi proposto que os dados sejam criptografados, assim ele avaliou o impacto da criptografia, foi realizado um estudo com os Bancos de Dados Cassandra e Hbase. 
Para tal foi utilizado o \emph{framework} YCSB em que~\emph{workloads} foram aplicadas a dados não-encriptados e encriptados usando o algoritmo~\emph{Advanced Encryption Standard} (AES) com chaves de diferentes comprimentos. 
Foi relatada uma redução no desempenho médio do~\emph{cluster}, o qual é independente do tamanho da chave de encriptação.

Na apresentação do  YCSB,~\cite{cooper2010benchmarking} aplicaram~\emph{benchmarking} para o Cassandra, Hbase, Yahoo!’s PNUTS e o Sharded MySQL, como exemplo de uso do \textit{framework}. 
Observou-se que o Cassandra e Hbase apresentam maior latência para operações~\emph{read} e menor latência para~\emph{update} e~\emph{write} em relação ao PNUTS e MySQL, enquanto o PNUTS e Cassandra possuem melhor escalabilidade em detrimento ao HBase, quando o número de servidores aumenta proporcionalmente a carga de trabalho.

Diferentemente da literatura, este trabalho avalia o potencial do escalonamento horizontal de um~\emph{cluster} Hbase, através de um \textit{benchmarking}, de modo a criar um cenário que aplicações e serviços se mantenham eficientes e disponíveis independentemente da demanda de armazenamento e consultas, em termos de eficiência e disponibilidade.

\section{Configuração do Ambiente de Experimentação}
\label{sec:conf-experimento}

Os testes foram executados em um~\emph{cluster} composto por 7 computadores com Linux CentOS 6.6, sendo um deles o nó mestre denominado hpcdmc e os seis caracterizados como nós escravos denominados de $n_1$ a $n_6$. \textbf{Configuração do nó mestre (hpcdmc):} 2x Processador Intel Xeon E5-2620 2.0GHz 6 núcleos; 4x Memória Ram Kingston DDR3 8GB 1333MHz; 8x Sata3 de 2TB. \textbf{Configuração dos nós escravos e cliente ($n_1$ a $n_6$):} 2x Processador Intel Xeon E5-2690 2.90GHz 8 núcleos; 4x Memória Ram Kingston DDR3 8GB 1600MHz; 8x Sata3 de 500GB e 16MB de cache.

%Configuração do nó mestre (hpcdmc):
%\begin{itemize}
%\item Sistema Operacional Linux CentOS 6.6
%\item 2x Processador Intel Xeon E5-2620 2.0GHz 6 núcleos
%\item 4x Memória Ram Kingston DDR3 8GB 1333MHz
%\item 8x Sata3 de 2TB
%\end{itemize}
%Configuração dos nós escravos e cliente ($n_1$ a $n_6$):
%\begin{itemize}
%\item Sistema Operacional Linux CentOS 6.6
%\item 2x Processador Intel Xeon E5-2690 2.90GHz 8 núcleos
%\item 4x Memória Ram Kingston DDR3 8GB 1600MHz
%\item 8x Sata3 de 500GB e 16MB de cache
%\end{itemize}
O experimento utilizou os softwares: Hadoop 2.7.3; HBase 1.2.4; ZooKeeper 3.4.10; YCSB 0.12.0, em que foi priorizada estabilidade na escolha das versões.

Para os testes iniciais foram organizados cinco cenários. 
Com base nesses foi analisado a melhor alternativa para a implementação do~\emph{cluster} e avaliar sua escalabilidade, ou seja, como serão dispostos os processos cliente, mestre e escravo, e assim foi idealizado e avaliado o sexto cenário.

Nos cinco primeiros cenários foram executados os testes em um ambiente pseudo distribuído, com duas~\emph{workloads}: 100\%~\emph{write} e 100\%~\emph{read} -- 100.000 registros, tendo cada registro 1KB e distribuição uniforme. Cada teste sobre uma~\emph{workload} foi executado 3 vezes para uma dada quantidade de~\emph{threads} do YCSB \textit{Client}, foi obtido a média da latência (tempo de execução em milissegundos) e do desempenho médio (operações/segundo) para obter o resultado final do teste.

No sexto cenário, cuja configuração foi obtida dos testes anteriores, é analisada a escalabilidade do HBase em um~\emph{cluster} totalmente distribuído. Cada teste foi executado 3 vezes, cujo resultado a média das saídas. A seguir é descrita a organização dos cenários:

\begin{figure}
	\centering
	\hspace{0.2cm}
    \begin{subfigure}{0.2\textwidth}
    	\centering
        \includegraphics[width=1.0\textwidth]{images/cenario-1.png}
        \caption{Cenário 1}
        \label{figura2a}
    \end{subfigure}
    \hspace{0.3cm}
    \begin{subfigure}{0.3\textwidth}   
    	\centering
        \includegraphics[width=1.1\textwidth]{images/cenario-2.png}
        \caption{Cenário 2}%
        \label{figura2b}
    \end{subfigure}
    \hspace{0.4cm}
    \begin{subfigure}{0.3\textwidth}
    	\centering
        \includegraphics[width=1.1\textwidth]{images/cenario-3.png}
        \caption{Cenário 3}
        \label{figura2c}
    \end{subfigure}
    \medskip
    \begin{subfigure}{0.3\textwidth}   
    	\centering
        \includegraphics[width=1.0\textwidth]{images/cenario-4.png}
        \caption{Cenário 4}%
        \label{figura2d}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
    	\centering
        \includegraphics[width=1.0\textwidth]{images/cenario-5.png}
        \caption{Cenário 5}
        \label{figura2e}
    \end{subfigure}
    \begin{subfigure}{0.35\textwidth}   
    	\centering
        \includegraphics[width=1.0\textwidth]{images/cenario-6.png}
        \caption{Cenário 6}%
        \label{figura2f}
    \end{subfigure}
    \caption{Configuração dos seis cenários de testes.}
\end{figure}

%\subsection{Cenário 1}
\textbf{Cenário 1:} o~\emph{cluster} é configurado como se houvesse uma distribuição entre máquinas em redes, porém estão todos no mesmo nó. 
Dessa forma, os processos mestre e escravo do Hadoop e HBase, os processos do ZooKeeper e do YCSB \emph{Client} são executados todos no hpcdmc~--~Figura~\ref{figura2a}.

%\subsection{Cenário 2}
\textbf{Cenário 2:} a execução de todos os processos mestre e escravo junto com o YCSB \emph{Client} pode comprometer a quantidade de requisições enviadas ao banco, alocou-se o YCSB em um nó separado para verificar essa hipótese. 
Assim, os processos meste e escravo do Hadoop e HBase e os processos do ZooKeeper continuaram a ser executados no hpcdmc, mas o processo YCSB \emph{Client} foi executado no nó $n_1$~--~Figura~~\ref{figura2b}.

%\subsection{Cenário 3}
\textbf{Cenário 3:} dada a limitação de~\emph{threads} do YCSB \emph{Client}, que podem ser executadas no $n_1$, pelo número de núcleos do processador, no cenário 3 a execução da~\emph{workload} foi dividida entre nós $n_1$ e $n_2$. 
Cada nó foi encarregado pela metade dos registros e metade do número de~\emph{threads} do YCSB \emph{Client} total do teste. 
Exemplo: na execução da~\emph{workload} 100\%~\emph{read} e 64~\emph{threads}, cada nó gerou 50.000 requisições~\emph{read} com 32~\emph{threads} ativas no YCSB. 
A saída de cada foi a soma do desempenho médio (operações/segundo) e a maior latência (tempo de execução em milissegundos). 
O hpcdmc permaneceu pseudo distribuído~--~Figura~\ref{figura2c}.

%\subsection{Cenário 4}
\textbf{Cenário 4:} consiste na aproximação de uma situação mais adequada quanto a configuração do~\emph{cluster}, em que os processos cliente, mestre e escravo estão completamente distribuídos. 
O $n_1$ é responsável pelo YCSB \textit{Client}, o hpcdmc pelos processos mestre do Hadoop, HBase e dos processos do ZooKeeper, enquanto o $n_2$ executou os processos escravos do Hadoop e HBase~--~Figura~\ref{figura2d}.

%\subsection{Cenário 5}
\textbf{Cenário 5:} analisou a necessidade de mais de um servidor gerando requisições na saturação do~\emph{cluster}. 
Assim, o $n_1$ e $n_2$ dividiram a execução das~\emph{workloads}, o hpcdmc foi responsável pelos processos mestre do Hadoop, HBase e os processos do ZooKeeper e o $n_3$ executou os processos escravos do Hadoop e HBase~--~Figura~\ref{figura2e}.

%\subsection{Cenário 6}
\textbf{Cenário 6:} Os resultados dos testes anteriores apoiaram as decisões quanto a estrutura do cenário 6~--~Figura~\ref{figura2f}. Foram executadas as~\emph{workloads}:~\emph{write},~\emph{read} e~\emph{scan}, variando entre 1.000, 10.000, 100.000 e 1.000.000 registros de tamanho 1KB e com distribuição uniforme, variando o número de escravos de 1 a 5 e o número de~\emph{threads} do YCSB \textit{Client} fixo.

\section{Análise dos Resultados}
\label{sec:resultados}

Essa Seção apresenta a análise dos resultados com a execução dos testes. Inicialmente são descritas as análises dos resultados obtidos nos cinco primeiros cenários, em seguida apresentamos as análises dos resultados dos testes aplicados em um~\emph{cluster} totalmente distribuído, cenário 6.

\subsection{Cenários de 1 a 5}

Analisando os resultados dos teste aplicados aos cenários 1 e 2 foi identificado um crescimento no desempenho médio do~\emph{cluster} nas execuções com o uso de até 64~\emph{threads} -- Figuras~\ref{figura11} e~\ref{figura13}. 
No cenário 1, ao utilizar entre uma e 64~\emph{threads} ocorreu um aumento de aproximadamente 90\% no desempenho médio, enquanto no cenário 2 ocorreu, para a mesma quantidade de~\emph{threads}, um aumento de aproximadamente 93\%.

Na instanciação de mais de 64~\emph{threads}, ao analisar os resultados obtidos com os testes aplicados ao cenário 1, observa-se queda no desempenho médio de aproximadamente 5\% com o uso de 128~\emph{threads}. Considerando o cenário 2, também há quedas nas execuções de 128, 256 e 512~\emph{threads}, sendo a mais expressiva de aproximadamente 10\% nas execuções com 256~\emph{threads}. 
Ambas as porcentagens foram calculadas comparando os resultados às execuções com 64~\emph{threads}.

Observa-se queda na latência nos testes dos cenários 1 e 2 até as execuções com 64~\emph{threads} -- Figuras~\ref{figura12} e~\ref{figura14}, a medida que o desempenho médio aumenta, ou seja, o~\emph{cluster} executa mais operações por segundo, o tempo de execução do teste diminui. No cenário 1, a queda da latência entre as execuções com 1 e 64~\emph{threads} foi de aproximadamente 90\% e para o cenário 2 de aproximadamente 93\%.

Constata-se que o desempenho máximo do~\emph{cluster} nos dois primeiros cenários foi obtido nas execuções do YCSB \textit{Client} com o uso de 64~\emph{threads}, a partir do cenário 3 foram executados apenas os testes com o uso de 64 a 512~\emph{threads}, de modo a observar se esses resultados foram ótimos locais ou globais. Os testes do cenário 1, para 256 e 512~\emph{threads} não puderam ser executados por estouro da pilha de memória do nó hpcdmc ao executar o YCSB \textit{Client} já que, além do YCSB \textit{Client} o nó hpcdmc também estava executando os processos mestre e escravo do Hbase e Hadoop e os processos do ZooKeeper.

A análise dos resultados dos testes com~\emph{workload} 100\%~\emph{write} -- 100.000 registros, mostrou que o melhor desempenho médio foi alcançado pelo cenário 5 para as execuções com o uso de 64 e 128~\emph{threads}, sendo maior que os resultados dos cenários 4, 3, 2 e 1 aproximadamente 5,7\%, 19,4\%, 25,4\% e 50,3\% nas execuções com 64 \emph{threads} e, 8,2\%, 27,4\%, 28,6\% e 54\% nas execuções com 128~\emph{threads}, respectivamente. 
Nas execuções com o uso de 256 e 512~\emph{threads} o melhor desempenho médio foi obtido pelo cenário 4 sendo maior que os cenários 5, 3 e 2 em 0,8\%, 22,6\% e 35,6\% nas execuções com 256~\emph{threads} e, 58\%, 19,9\% e 21,2\% nas execuções com 512~\emph{threads} respectivamente.

\begin{figure*}
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/figura11}
        \caption{Desempenho médio}
        \label{figura11}
    \end{subfigure}
        \hfill
    \begin{subfigure}[b]{0.49\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{images/figura12}
        \caption{Latência}%
        \label{figura12}
    \end{subfigure}
    \caption{\emph{Workload} 100\%~\emph{write} 100.000 registros nos cenários de 1 a 5.}
\end{figure*}

\begin{figure*}
    \centering
    \begin{subfigure}[b]{0.49\textwidth}   
        \centering 
        \includegraphics[width=\textwidth]{images/figura13}
        \caption{Desempenho médio}
        \label{figura13}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}   
        \centering 
        \includegraphics[width=\textwidth]{images/figura14}
        \caption{Latência}
        \label{figura14}
    \end{subfigure}
    \caption{\emph{Workload} 100\%~\emph{read} 100.000 registros nos cenários de 1 a 5.}
\end{figure*}

O cenário 5 apresentou esse desempenho pois o~\emph{cluster} foi completamente distribuído, então os processos mestres e escravo do Hbase e Hadoop, processos do ZooKeeper e YCSB não concorreram por recursos de uma mesma máquina uns com os outros. O mesmo ocorreu no cenário 4, mas a divisão da execução das~\emph{workloads} entre o $n_1$ e $n_2$ apresentou uma pequena melhora no cenário 5 no desempenho do~\emph{cluster} executando o YCSB com 64 e 128~\emph{threads}, já nas execuções com o uso de 256 e 512~\emph{threads} tal divisão sobrecarregou demais o $n_3$ fazendo com que o desempenho médio diminuísse e a latência aumentasse, tornando os resultados do cenário 4 melhores.

A partir dos testes com a~\emph{workload} 100\%~\emph{write} -- 100.000 registros, pode-se concluir que o cenário 5, para execuções com o uso de 64 e 128~\emph{threads} obteve uma execução mais rápida se comparado com os resultados obtidos com os testes dos cenários 4, 3, 2 e 1 aproximadamente 5,6\%, 19,7\%, 25,4\% e 50,2\% com o uso de 64~\emph{threads} e, 7,8\%, 27\%, 28,1\% e 53,7\% com 128~\emph{threads} respectivamente. Enquanto que as execuções com o uso de 256 e 512~\emph{threads} o cenário 4 apresentou resultados nos quais a execução foi mais rápida que os resultados obtidos com os testes dos cenários 5, 3 e 2 aproximadamente 2,4\%, 22,8\% e 35,8\% com o uso de 256 \emph{threads} e, 95,8\%, 20,3\% e 21,5\% com o uso de 512~\emph{threads} -- Figura~\ref{figura12}.

Considerando a~\emph{workload} 100\%~\emph{read} -- 100.000 registros, para todos os números de~\emph{threads}, o cenário 5 apresentou resultados com o melhor desempenho médio sendo maior que os resultados dos cenários 4, 3, 2 e 1 aproximadamente 26,8\%, 22,2\%, 48,3\% e 62,6\% nas execuções com o uso de 64~\emph{threads} e, 26,9\%, 44,3\%, 45,7\% e 64,4\% nas execuções com o uso de 128~\emph{threads} respectivamente. E maior que os resultados dos cenários 4, 3 e 2 aproximadamente 28,4\%, 23\% e 50,4\% nas execuções com o uso de 256~\emph{threads} e, 26,5\%, 18,2\% e 47,3\% nas execuções com o uso de 512~\emph{threads} respectivamente.

Para as operações de leitura na~\emph{workload} 100\%~\emph{read}, a divisão de requisições entre o $n_1$ e $n_2$ não sobrecarregou o $n_3$ para execuções com o uso de 256 e 512 \emph{threads} como nos testes com a~\emph{workload} 100\%~\emph{write}, então o cenário 5 obteve os melhores resultados para cada execução entre 64 e 512~\emph{threads}. Os testes do cenário 3, que também dividiram as requisições entre o $n_1$ e $n_2$ obtiveram os segundos melhores resultados para cada execução entre 64 e 512~\emph{threads}. Portanto para operações de leitura, o~\emph{cluster} é mais eficiente, considerando o desempenho médio e a latência, se as requisições são realizadas de mais de um cliente -- Figura~\ref{figura13}.

Na~\emph{workload} 100\%~\emph{read} -- 100.000 registros -- Figura~\ref{figura14}, a latência obtida com os testes executados no cenário 5 foi menor que os cenários 4, 3, 2 e 1 aproximadamente 26,2\%, 22,8\%, 47,9\% e 62,3\% nas execuções com o uso de 64~\emph{threads} e, 26,6\%, 23,6\%, 45,6\% e 64,3\% nas execuções com o uso de 128~\emph{threads} respectivamente. E também, menor que os cenários 4, 3 e 2 aproximadamente 27,9\%, 22,8\% e 50\% nas execuções com o uso de 256~\emph{threads} e, 25,5\%, 17,3\% e 46.6\% nas execuções com o uso de 512~\emph{threads} respectivamente.

Observou-se também que para todos os cenários as execuções com o uso de 64 e 128~\emph{threads} são as mais altas e a variação referente a um mesmo cenário, considerando essas duas quantidades de~\emph{threads} não são expressivas, sendo de aproximadamente 1\%, para os testes da~\emph{workload} 100\%~\emph{write} e 100\%~\emph{read}, para latência e desempenho médio. 
O aumento do número de~\emph{threads} além de 128 causou uma queda do desempenho médio nos testes dos cenários 5, 4, 3 e 2 de até 65\%, 9,3\%, 15\% e 9,6\% para os testes da~\emph{workload} 100\%~\emph{write} e, 10,9\%, 10,4\%, 5,3 e 13,5\% para os testes da~\emph{workload} 100\%~\emph{read} respectivamente. Comparando então os 5 cenários em que a execução do YCSB \emph{Client} ocorreu com 64~\emph{threads}, temos que em ambas as~\emph{workloads} 100\%~\emph{write} e 100\%~\emph{read} o cenário 5 obteve o maior desempenho médio do~\emph{cluster}, seguido pelo cenário 4 na~\emph{workload} 100\%~\emph{write} com uma diferença de aproximadamente 5,7\% e, seguido pelos cenários 3 e 4 na~\emph{workload} 100\%~\emph{read} com uma diferença de aproximadamente 22,2\% e 26,8\% respectivamente.

O cenário 4 obteve o segundo maior desempenho médio com a~\emph{workload} 100\%~\emph{write} com menos de 6\% comparado ao cenário 5, obtendo o terceiro maior desempenho médio nos testes da~\emph{workload} 100\%~\emph{read} com uma diferença de aproximadamente 6\% comparado com os resultados obtidos com os testes aplicados ao cenário 3 e, considerando também que ambos os cenários 5 e 3 utilizam 2 nós para a execução do YCSB \emph{Client}, reduzindo o número de nós disponíveis para os testes de adição de nós, a implementação do~\emph{cluster} para os testes do cenário 6 foi realizada de acordo com o cenário 4 e com 64~\emph{threads} de execução no YCSB \emph{Client}.

\subsection{Cenário 6}
\label{subsec:resultado-cenario-6}

Inicialmente, a respeito do desempenho médio (Figura~\ref{figura15}), a escalabilidade horizontal foi mais evidenciada com 1.000.000 de registros, sendo o desempenho do~\emph{cluster} com 5~\emph{region servers} maior do que os testes executados com 4, 3, 2, e 1~\emph{region servers} em aproximadamente 5,1\%, 6,5\%, 17,1\% e 47\% respectivamente. A análise dos resultados dos testes para 100.000 registros também demonstraram certa escalabilidade, sendo o desempenho médio com 5~\emph{region servers} maior do que o desempenho médio dos testes executados com 4, 3, 2, e 1~\emph{region servers} em aproximadamente 9,9\%, 10,4\%, 15,7\% e 43,4\% respectivamente.

\begin{figure*}[!ht]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/figura15}
        \caption{Desempenho médio}
        \label{figura15}
    \end{subfigure}
        \hfill
    \begin{subfigure}[b]{0.49\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{images/figura16}
        \caption{Latência}
        \label{figura16}
    \end{subfigure}
    \caption{\emph{Workload} 100\%~\emph{write} variando o tamanho do conjunto de dados e o número de~\emph{region servers} do~\emph{cluster} .}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/figura17}
        \caption{Desempenho médio}
        \label{figura17}
    \end{subfigure}
        \hfill
    \begin{subfigure}[b]{0.49\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{images/figura18}
        \caption{Latência}%
        \label{figura18}
    \end{subfigure}
    \caption{\emph{Workload} 100\%~\emph{read} variando o tamanho do conjunto de dados e o número de \emph{region servers} do~\emph{cluster}.}
\end{figure*}

A partir da análise dos resultados dos testes da~\emph{workload} 100\%~\emph{write}~--~Figura~\ref{figura16}, observa-se que com 1.000.000 registros a latência foi menor que os testes com 4, 3, 2 e 1 \emph{region server} em aproximadamente 5\%, 6,3\%, 17,1\% e 47\% respectivamente. 
Com base nos testes com 100.000 registros, a escalabilidade foi menos evidenciada, as latências tiveram poucas alterações comparados com os resultados dos testes com 4, 3, 2 e 1 \emph{region server}, sendo menor em aproximadamente 12,5\%, 11,7\%, 15,9\% e 43,4\% respectivamente.

Nos testes com conjunto de dados de 1.000 e 10.000 registros não houve alterações significativas no desempenho médio com a adição de nós, sendo a variação mais expressiva para 1.000 registros de aproximadamente 4\% aumentando de 1 para 2~\emph{region servers}, aproximadamente 8\% para 10.000 aumentando de 1 para 2 \emph{region servers}, considerando o desempenho médio~--~Figura~\ref{figura17} e a latência~--~Figura~\ref{figura18}.

Para a~\emph{workload} 100\%~\emph{read}, assim como nos resultados acima, nota-se que a escalabilidade horizontal foi mais evidenciada quando o conjunto com 1.000.000 de registros. Porém nas execuções com 5 \emph{region servers} só existiu alteração significativa no desempenho médio quando comparadas com as execuções com 2 e 1 \emph{region servers}, sendo maior em aproximadamente 10,4\% e 39,1\% respectivamente. Para as execuções com 4 e 3~\emph{region servers} a variação foi de menos de 1,5\%~--~Figura~\ref{figura17}. Pelos resultados dos testes com 100.000 registros, nota-se o mesmo comportamento, sendo o desempenho médio das execuções com 5~\emph{region servers} maior que os testes com 2 e 1~\emph{region servers} aproximadamente 5,4\% e 29\% respectivamente. 
Para as execuções com 4 e 3~\emph{region servers} a variação foi de menos de 2,4\%. Os testes em que os conjuntos de dados foram iguais a 1.000 e 10.000 registros não tiveram alterações significativas, sendo a variação mais expressiva para o conjunto de dados de 1.000 registros de menos de 1,5\% aumentando de 1 para 2~\emph{region servers} e para o conjunto de 10.000 registros de menos de 7,5\% também aumentando de 1 para 2~\emph{region servers}.

A latência dos testes da~\emph{workload} 100\%~\emph{read}~--~Figura~\ref{figura18}, também não apresentou alterações significativas para os testes com 1.000.000 e 100.000 registros quando variados os~\emph{region servers} entre 3 e 5, sendo essa variação menor que 1,3\% para ambos. 
Desta forma, os testes executados com 5~\emph{region servers} apresentaram menor latência que os testes com 2 e 1~\emph{region servers} em aproximadamente 10,5\% e 40,2\% com 1.000.000 de registros e, em aproximadamente 5,4\% e 29\% com 100.000 registros respectivamente. Para 1.000 e 10.000 registros não houve alterações significativas no desempenho médio, sendo a variação de 1 para 5 \emph{region servers} menor que 3,3\% para 1.000 registros e, de menos de 10,7\% para 10.000 registros.

\begin{figure*}[!ht]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/figura19}
        \caption{Desempenho médio}
        \label{figura19}
    \end{subfigure}
        \hfill
    \begin{subfigure}[b]{0.49\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{images/figura20}
        \caption{Latência}%
        \label{figura20}
    \end{subfigure}
    \caption{\emph{Workload} 100\%~\emph{read/modify/write} variando o tamanho do conjunto de dados e o número de \emph{region servers} do \emph{cluster}.}
\end{figure*}

\begin{figure*}
    \centering
    \begin{subfigure}[b]{0.49\textwidth}   
        \centering 
        \includegraphics[width=\textwidth]{images/figura21}
        \caption{Desempenho médio}
        \label{figura21}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}   
        \centering 
        \includegraphics[width=\textwidth]{images/figura22}
        \caption{Latência}
        \label{figura22}
    \end{subfigure}
    \caption{\emph{Workload} 100\% scan variando o tamanho do conjunto de dados e o número de \emph{region servers} do \emph{cluster}.}
\end{figure*}

Quanto ao desempenho médio dos testes da~\emph{workload} 100\%~\emph{read}/modify/write~--~Figura~\ref{figura19}, observou-se novamente que, a escalabilidade horizontal é mais evidenciada nos cenários com 1.000.000 de registros, sendo o desempenho médio dos testes com 5~\emph{region servers} maior que os resultados dos testes com 4, 3, 2 e 1~\emph{region servers} aproximadamente 4,5\%, 14,5\%, 29,7\% e 58,6\% respectivamente. 
Para os testes com 100.000 registros obteve-se nas execuções com 5~\emph{region servers} um desempenho médio maior que os testes com 4, 3, 2 e 1 \emph{region server} de aproximadamente 5,6\%, 7,1\%, 20,1\% e 47,7\% respectivamente.

Os testes com 1.000 registros não apresentaram resultados com alterações significativas no desempenho médio, a variação mais expressiva é de menos de 6\% aumentando de 1 para 2 \emph{region servers}. No conjunto de 10.000 registros, a variação mais expressiva foi de 18,5\% quando aumentado de 1 para 2 \emph{region servers}. As demais adições variaram menos que 4\%.

Considerando a \emph{workload} 100\%~\emph{read/modify/write} o comportamento da latência -- Figura~\ref{figura20}, acompanha o desempenho médio de modo inversamente proporcional, assim, os testes com 1.000.000 de registros e 5~\emph{region servers} obtiveram uma latência menor que os testes com 4, 3, 2 e 1~\emph{region servers} em aproximadamente 4,4\%, 14,4\%, 29,9\% e 58,7\% respectivamente. Do mesmo modo, com 100.000 registros e 5 \emph{region servers} houve latência menor que os testes com 4, 3, 2 e 1 \emph{region servers} em aproximadamente 2,6\%, 7,7\%, 20,1\% e 47,9\% respectivamente.

Os testes com a~\emph{workload} 100\%~\emph{read/modify/write} de 1.000 e 10.000 registros não tiveram alterações significativas na latência, seguindo a mesma porcentagem calculada nos testes de desempenho médio. O desempenho médio -- Figura~\ref{figura21} e latência -- Figura~\ref{figura22} para os testes da~\emph{workload} 100\%~\emph{scan}, mostra-se que, exceto com 1.000 registros, que não houve alterações significativas no desempenho médio do~\emph{cluster} sendo a variação mais expressiva de todos os conjuntos menor que 1,4\%. 
%Portanto também não houve alteração significativa na latência em nenhum testes executados.

Nos testes com 1.000 registros, o desempenho médio das execuções com 5~\emph{region servers} foi maior que do as execuções com 4, 3, 2 e 1~\emph{region servers} em aproximadamente 5,5\%, 2,4\%, 7\% e 42,5\% respectivamente. A latência das execuções com 5~\emph{region servers} foi menor que do as execuções com 4, 3, 2 e 1~\emph{region servers} em aproximadamente 5,3\%, 2,2\%, 6,5\% e 42\% respectivamente.

\section{Considerações Finais}
\label{sec:finais}

%Este trabalho analisou a escalabilidade horizontal de um~\emph{cluster}  Hbase, submetendo o banco de dados a um \textit{benchmarking} apoiado pela ferramenta YSCB. Foram conduzidos testes com diferentes números de nós-escravos e tamanho do conjunto de dados.

Os resultados obtidos mostram que o escalonamento horizontal é mais evidente, considerando as~\emph{workloads} 100\%~\emph{write},~\emph{read} e~\emph{read/modify/write}, para conjuntos superiores a cem mil registros. Também foi identificado que o desempenho médio do~\emph{cluster} é mais significativo no aumento de~\emph{region servers} de 1 para 2 e de 2 para 3, sendo menos expressivos a partir de 3~\emph{region servers} (inferior a 8\%). 

Desta forma, a melhora no desempenho do~\emph{cluster} Hbase, considerando o desempenho médio e a latência das operações, é diretamente proporcional ao tamanho do conjunto de dados, de modo mais evidente.

O ganho de desempenho varia de acordo com as operações. Por exemplo, o melhor aproveitamento do~\emph{cluster} para desempenho médio nas execuções com 5~\emph{region servers} foi alcançado pelos testes da~\emph{workload} 100\%~\emph{read}, sendo maior que os testes das~\emph{workloads} 100\%~\emph{write} e 100\%~\emph{read/modify/write} em aproximadamente 22\% e 28\% respectivamente. 
Contudo, os testes da~\emph{workload} 100\%~\emph{scan} mostram que não há melhora no desempenho para busca, independentemente do conjunto de dados, devido a implementação da busca linear implementada pela ferramenta Hbase.

%Os trabalhos futuros podem explorar o aumento do fator de replicação, não empregado neste trabalho, ao analisar o impacto que as operações adicionais de replicação podem causar à eficiência do~\emph{cluster}, considerando a inserção de novos nós.

\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}